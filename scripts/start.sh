#!/bin/bash
# Semantika - Script de Inicio Automatizado
# Inicia todos los servicios y configura el sistema completo

set -e  # Salir si alg√∫n comando falla

# Colores para output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Funciones de logging
log_info() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

log_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

log_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

# Funci√≥n para verificar si un comando existe
command_exists() {
    command -v "$1" >/dev/null 2>&1
}

# Funci√≥n para esperar que un servicio est√© listo
wait_for_service() {
    local service_name=$1
    local url=$2
    local max_attempts=${3:-30}
    local attempt=1
    
    log_info "Esperando que $service_name est√© listo..."
    
    while [ $attempt -le $max_attempts ]; do
        if curl -s "$url" >/dev/null 2>&1; then
            log_success "$service_name est√° listo!"
            return 0
        fi
        
        echo -n "."
        sleep 2
        attempt=$((attempt + 1))
    done
    
    log_error "$service_name no respondi√≥ despu√©s de $max_attempts intentos"
    return 1
}

# Funci√≥n principal
main() {
    log_info "üöÄ Iniciando Semantika RAG Design-System Assistant"
    
    # Verificar dependencias
    log_info "üîç Verificando dependencias..."
    
    if ! command_exists docker; then
        log_error "Docker no est√° instalado. Por favor instala Docker primero."
        exit 1
    fi
    
    if ! command_exists docker-compose; then
        log_error "Docker Compose no est√° instalado. Por favor instala Docker Compose primero."
        exit 1
    fi
    
    if ! command_exists python3; then
        log_error "Python 3 no est√° instalado. Por favor instala Python 3 primero."
        exit 1
    fi
    
    log_success "Todas las dependencias est√°n disponibles"
    
    # Navegar al directorio ra√≠z del proyecto
    PROJECT_ROOT="$(cd "$(dirname "${BASH_SOURCE[0]}")/.." && pwd)"
    cd "$PROJECT_ROOT"
    
    log_info "üìÇ Directorio del proyecto: $PROJECT_ROOT"
    
    # Crear archivo .env si no existe
    if [ ! -f "services/llm-service/.env" ]; then
        log_info "üìù Creando archivo .env para LLM service..."
        cat > "services/llm-service/.env" << EOF
# Configuraci√≥n de Base de Datos
PGHOST=localhost
PGPORT=5432
PGDATABASE=semantikadb
PGUSER=semantika
PGPASSWORD=semantika

# Configuraci√≥n de OpenAI
OPENAI_API_KEY=your_openai_api_key_here

# Configuraci√≥n del Servicio
LOG_LEVEL=INFO
ENVIRONMENT=development
EOF
        log_warning "‚ö†Ô∏è Recuerda configurar tu OPENAI_API_KEY en services/llm-service/.env"
    fi
    
    # Iniciar servicios de infraestructura
    log_info "üê≥ Iniciando servicios de infraestructura..."
    cd infra
    docker-compose up -d
    cd ..
    
    # Esperar que PostgreSQL est√© listo
    log_info "Verificando conexi√≥n a PostgreSQL..."
    if ! timeout 30 bash -c 'until pg_isready -h localhost -p 5432 -U semantika; do sleep 1; done' 2>/dev/null; then
        # Fallback: intentar conectar directamente
        if ! python3 -c "import psycopg; psycopg.connect('host=localhost port=5432 dbname=semantikadb user=semantika password=semantika')" 2>/dev/null; then
            log_warning "‚ö†Ô∏è PostgreSQL puede no estar completamente listo, pero continuando..."
        fi
    fi
    log_success "PostgreSQL est√° disponible"
    
    # Configurar entorno Python para LLM service
    log_info "üêç Configurando entorno Python..."
    cd services/llm-service
    
    if [ ! -d ".venv" ]; then
        log_info "Creando entorno virtual de Python..."
        python3 -m venv .venv
    fi
    
    log_info "Activando entorno virtual..."
    source .venv/bin/activate
    
    log_info "Verificando dependencias Python..."
    if ! python3 -c "import fastapi, uvicorn, openai, psycopg" 2>/dev/null; then
        log_info "Instalando dependencias Python..."
        pip install -q --upgrade pip
        pip install -q -r requirements.txt
    else
        log_success "Las dependencias ya est√°n instaladas"
    fi
    
    cd ../..
    
    # Verificar variables de entorno cr√≠ticas
    if [ -z "$OPENAI_API_KEY" ] && ! grep -q "sk-" services/llm-service/.env 2>/dev/null; then
        log_warning "‚ö†Ô∏è OPENAI_API_KEY no est√° configurada. El sistema funcionar√° con limitaciones."
        log_warning "   Configura tu API key en services/llm-service/.env para funcionalidad completa."
    fi
    
    # Inicializar datos (si la tabla est√° vac√≠a)
    log_info "üìä Verificando datos de componentes..."
    cd scripts
    # Usar el entorno virtual para verificar datos
    source ../services/llm-service/.venv/bin/activate
    if python3 -c "
import psycopg
try:
    with psycopg.connect('host=localhost port=5432 dbname=semantikadb user=semantika password=semantika') as conn:
        with conn.cursor() as cur:
            cur.execute('SELECT COUNT(*) FROM components;')
            count = cur.fetchone()[0]
            if count == 0:
                exit(1)  # Tabla vac√≠a
except:
    exit(1)  # Error de conexi√≥n
" 2>/dev/null; then
        log_success "Los datos ya est√°n inicializados"
    else
        log_info "Inicializando datos de componentes..."
        if [ -n "$OPENAI_API_KEY" ] || grep -q "sk-" ../services/llm-service/.env 2>/dev/null; then
            python3 update_embeddings.py
        else
            log_warning "Saltando generaci√≥n de embeddings (API key no configurada)"
        fi
    fi
    cd ..
    
    # Iniciar LLM Service
    log_info "üß† Iniciando LLM Service..."
    cd services/llm-service
    source .venv/bin/activate
    
    # Iniciar en background
    nohup uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload > ../../semantika-llm.log 2>&1 &
    LLM_PID=$!
    echo $LLM_PID > ../../semantika-llm.pid
    
    cd ../..
    
    # Esperar que LLM Service est√© listo
    if ! wait_for_service "LLM Service" "http://localhost:8000/health" 20; then
        log_error "LLM Service no se inici√≥ correctamente"
        exit 1
    fi
    
    # Mostrar informaci√≥n del sistema
    log_success "üéâ ¬°Semantika est√° ejecut√°ndose!"
    echo ""
    echo "üìã Informaci√≥n del Sistema:"
    echo "   üåê Frontend:          file://$(pwd)/frontend/ui/index.html"
    echo "   üß† LLM Service:       http://localhost:8000"
    echo "   üìö API Docs:          http://localhost:8000/docs"
    echo "   üóÑÔ∏è  Database Admin:    http://localhost:8080"
    echo "   üìä Health Check:      http://localhost:8000/health"
    echo ""
    echo "üìù Logs:"
    echo "   LLM Service: tail -f semantika-llm.log"
    echo "   Docker:      docker-compose -f infra/docker-compose.yml logs -f"
    echo ""
    echo "üõë Para detener:"
    echo "   ./scripts/stop.sh"
    echo ""
    
    # Abrir navegador si est√° disponible
    if command_exists open; then
        # macOS
        log_info "üåê Abriendo frontend en el navegador..."
        open "file://$(pwd)/frontend/ui/index.html"
    elif command_exists xdg-open; then
        # Linux
        log_info "üåê Abriendo frontend en el navegador..."
        xdg-open "file://$(pwd)/frontend/ui/index.html"
    fi
    
    log_success "‚úÖ Inicio completado exitosamente"
    log_info "üí° El sistema seguir√° corriendo en segundo plano"
    log_info "üõë Para detener todos los servicios ejecuta: ./scripts/stop.sh"
}

# Manejo de se√±ales para limpieza
cleanup() {
    log_info "üßπ Limpiando procesos en caso de error..."
    if [ -f "semantika-llm.pid" ]; then
        kill "$(cat semantika-llm.pid)" 2>/dev/null || true
        rm -f semantika-llm.pid
    fi
}

# Solo limpiar en caso de error, no al finalizar exitosamente
trap cleanup ERR

# Ejecutar funci√≥n principal
main "$@" 